
@article{li_measuring_2011,
	title = {Measuring reproducibility of high-throughput experiments},
	volume = {5},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/1110.4705},
	doi = {10.1214/11-AOAS466},
	abstract = {Reproducibility is essential to reliable scientific discovery in high-throughput experiments. In this work we propose a unified approach to measure the reproducibility of findings identified from replicate experiments and identify putative discoveries using reproducibility. Unlike the usual scalar measures of reproducibility, our approach creates a curve, which quantitatively assesses when the findings are no longer consistent across replicates. Our curve is fitted by a copula mixture model, from which we derive a quantitative reproducibility score, which we call the "irreproducible discovery rate" (IDR) analogous to the FDR. This score can be computed at each set of paired replicate ranks and permits the principled setting of thresholds both for assessing reproducibility and combining replicates. Since our approach permits an arbitrary scale for each replicate, it provides useful descriptive measures in a wide variety of situations to be explored. We study the performance of the algorithm using simulations and give a heuristic analysis of its theoretical properties. We demonstrate the effectiveness of our method in a ChIP-seq experiment.},
	language = {en},
	number = {3},
	urldate = {2023-10-31},
	journal = {The Annals of Applied Statistics},
	author = {Li, Qunhua and Brown, James B. and Huang, Haiyan and Bickel, Peter J.},
	month = sep,
	year = {2011},
	note = {arXiv:1110.4705 [stat]},
	annote = {Comment: Published in at http://dx.doi.org/10.1214/11-AOAS466 the Annals of Applied Statistics (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
	file = {Full Text PDF:/Users/agustin/Zotero/storage/FRGHZLMG/Li et al. - 2011 - Measuring reproducibility of high-throughput exper.pdf:application/pdf;Li et al. - 2011 - Measuring reproducibility of high-throughput exper.pdf:/Users/agustin/Zotero/storage/B67NHZJ3/Li et al. - 2011 - Measuring reproducibility of high-throughput exper.pdf:application/pdf},
}

@misc{gonzalez-reymundez_ecv_2023,
	title = {{eCV}: {Enhanced} coefficient of variation and {IDR} extensions for reproducibility assessment of high-throughput experiments with multiple replicates},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {{eCV}},
	url = {https://www.biorxiv.org/content/10.1101/2023.12.18.572208v3},
	doi = {10.1101/2023.12.18.572208},
	abstract = {Motivation Reproducibility assessment is essential in extracting reliable scientific insights from highthroughput experiments. Inconsistency between technical replicates poses a challenge, particularly clear in next generation sequencing technologies based on immunoprecipitations, where the assessment of reproducibility in peak identification is a critical analytical step. While the Irreproducibility Discovery Rate (IDR) method has been instrumental in assessing reproducibility, its standard implementation is constrained to handling only two replicates. In the current era of steadily growing sample sizes, eased by multiplexing and reduced sequencing costs, highly performing methods that handle any number of replicates are desirable.
Results We introduce three novel methods for reproducibility assessment in high-throughput data that handle an arbitrary number of replicates. The first, general IDR (gIDR), extends the standard IDR by adapting its Expectation-Maximization (EM) algorithm to handle distributions of any dimensions dictated by the number of replicates. The second, meta-IDR (mIDR), employs a meta-analysis approach, calculating local IDR scores for all pairs of replicates and combining them using standard probability rules. The third method introduces an “enhanced” Coefficient of Variation (eCV), ranking features based on intensity and variability, using a parametric bootstrap approach to obtain an index analogous to local IDR. Comparative analysis with traditional IDR in simulated and experimental data reveals the heightened performance of the proposed multivariate alternatives under varying scenarios, thereby addressing the critical challenge of reproducibility assessment in contemporary high-throughput experiments.
Availability and implementation The described methods are implemented as an R package: https://github.com/eclipsebio/eCV
Contact info\{at\}eclipsebio.com},
	language = {en},
	urldate = {2024-01-02},
	publisher = {bioRxiv},
	author = {Gonzalez-Reymundez, Agustin and Shen, Kylie and Doyle, Wayne and Peng, Sichong and Hutt, Kasey and Bruns, Stephanie},
	month = dec,
	year = {2023},
	note = {Pages: 2023.12.18.572208
Section: New Results},
	file = {Full Text PDF:/Users/agustin/Zotero/storage/7ITTFAW7/Gonzalez-Reymundez et al. - 2023 - eCV Enhanced coefficient of variation and IDR ext.pdf:application/pdf},
}
